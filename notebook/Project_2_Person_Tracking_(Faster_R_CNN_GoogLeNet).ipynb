{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Drive Setup"
      ],
      "metadata": {
        "id": "5MPQuNvIQ-NW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is to store the dataset and trained models"
      ],
      "metadata": {
        "id": "V7K3Mck1S6ln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsrV9CTLI0x2",
        "outputId": "3640ed08-6e81-4420-a560-a9c399878a29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive_dataset_path = '/content/drive/MyDrive/cv_bootcamp_indonesiaai/project_2/dataset'"
      ],
      "metadata": {
        "id": "CrhZXZGEI1PW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Data"
      ],
      "metadata": {
        "id": "PU_TmtuyJRoM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use `coco 2017` dataset from FiftyOne"
      ],
      "metadata": {
        "id": "6uT_T0SBR2FA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fiftyone\n",
        "!pip install fiftyone-db-ubuntu2204"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mx8e3GtnJTZX",
        "outputId": "804b3532-31a4-4c24-fc39-468af8dfe41c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fiftyone in /usr/local/lib/python3.10/dist-packages (0.22.3)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.10/dist-packages (from fiftyone) (23.2.1)\n",
            "Requirement already satisfied: argcomplete in /usr/local/lib/python3.10/dist-packages (from fiftyone) (3.1.6)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (4.11.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.33.4)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.3.2)\n",
            "Requirement already satisfied: dacite<1.8.0,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.7.0)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.2.14)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from fiftyone) (6.1.3)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from fiftyone) (4.7.0)\n",
            "Requirement already satisfied: hypercorn>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.15.0)\n",
            "Requirement already satisfied: Jinja2>=3 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (3.1.2)\n",
            "Requirement already satisfied: kaleido!=0.2.1.post1 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.2.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from fiftyone) (3.7.1)\n",
            "Requirement already satisfied: mongoengine==0.24.2 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.24.2)\n",
            "Requirement already satisfied: motor>=2.5 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (3.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fiftyone) (23.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.5.3)\n",
            "Requirement already satisfied: Pillow>=6.2 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (9.4.0)\n",
            "Requirement already satisfied: plotly>=4.14 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.15.0)\n",
            "Requirement already satisfied: pprintpp in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.9.5)\n",
            "Requirement already satisfied: pymongo>=3.12 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (4.6.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from fiftyone) (2023.3.post1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from fiftyone) (6.0.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fiftyone) (2023.6.3)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.3.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.2.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.19.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from fiftyone) (67.7.2)\n",
            "Requirement already satisfied: sseclient-py<2,>=1.7.2 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.8.0)\n",
            "Requirement already satisfied: sse-starlette<1,>=0.10.3 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.10.3)\n",
            "Requirement already satisfied: starlette>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.32.0.post1)\n",
            "Requirement already satisfied: strawberry-graphql==0.138.1 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.138.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.9.0)\n",
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.13.0)\n",
            "Requirement already satisfied: universal-analytics-python3<2,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.1.1)\n",
            "Requirement already satisfied: fiftyone-brain~=0.13.2 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.13.4)\n",
            "Requirement already satisfied: fiftyone-db~=0.4 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.4.0)\n",
            "Requirement already satisfied: voxel51-eta~=0.12 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.12.0)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from fiftyone) (4.8.1.78)\n",
            "Requirement already satisfied: graphql-core<3.3.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from strawberry-graphql==0.138.1->fiftyone) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from strawberry-graphql==0.138.1->fiftyone) (2.8.2)\n",
            "Requirement already satisfied: typing_extensions<5.0.0,>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from strawberry-graphql==0.138.1->fiftyone) (4.5.0)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from fiftyone-brain~=0.13.2->fiftyone) (1.11.3)\n",
            "Requirement already satisfied: h11 in /usr/local/lib/python3.10/dist-packages (from hypercorn>=0.13.2->fiftyone) (0.14.0)\n",
            "Requirement already satisfied: h2>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from hypercorn>=0.13.2->fiftyone) (4.1.0)\n",
            "Requirement already satisfied: priority in /usr/local/lib/python3.10/dist-packages (from hypercorn>=0.13.2->fiftyone) (2.0.0)\n",
            "Requirement already satisfied: taskgroup in /usr/local/lib/python3.10/dist-packages (from hypercorn>=0.13.2->fiftyone) (0.0.0a4)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from hypercorn>=0.13.2->fiftyone) (2.0.1)\n",
            "Requirement already satisfied: wsproto>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from hypercorn>=0.13.2->fiftyone) (1.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3->fiftyone) (2.1.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.14->fiftyone) (8.2.3)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo>=3.12->fiftyone) (2.4.2)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette>=0.24.0->fiftyone) (3.7.1)\n",
            "Requirement already satisfied: httpx>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from universal-analytics-python3<2,>=1.0.1->fiftyone) (0.25.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from voxel51-eta~=0.12->fiftyone) (0.3.7)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from voxel51-eta~=0.12->fiftyone) (0.18.3)\n",
            "Requirement already satisfied: glob2 in /usr/local/lib/python3.10/dist-packages (from voxel51-eta~=0.12->fiftyone) (0.7)\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.10/dist-packages (from voxel51-eta~=0.12->fiftyone) (4.0.0)\n",
            "Requirement already satisfied: py7zr in /usr/local/lib/python3.10/dist-packages (from voxel51-eta~=0.12->fiftyone) (0.20.8)\n",
            "Requirement already satisfied: rarfile in /usr/local/lib/python3.10/dist-packages (from voxel51-eta~=0.12->fiftyone) (4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from voxel51-eta~=0.12->fiftyone) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from voxel51-eta~=0.12->fiftyone) (1.16.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from voxel51-eta~=0.12->fiftyone) (2.4.0)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from voxel51-eta~=0.12->fiftyone) (5.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from voxel51-eta~=0.12->fiftyone) (2.0.7)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->fiftyone) (2.5)\n",
            "Requirement already satisfied: botocore<1.34.0,>=1.33.4 in /usr/local/lib/python3.10/dist-packages (from boto3->fiftyone) (1.33.4)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->fiftyone) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.9.0,>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from boto3->fiftyone) (0.8.2)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->fiftyone) (1.14.1)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->fiftyone) (0.2.12)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (3.1.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (3.2.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (2023.9.26)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (1.4.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fiftyone) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fiftyone) (3.2.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone) (1.1.3)\n",
            "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.10/dist-packages (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone) (6.0.1)\n",
            "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.10/dist-packages (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone) (4.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (2023.7.22)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (1.0.2)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->voxel51-eta~=0.12->fiftyone) (23.1.0)\n",
            "Requirement already satisfied: texttable in /usr/local/lib/python3.10/dist-packages (from py7zr->voxel51-eta~=0.12->fiftyone) (1.7.0)\n",
            "Requirement already satisfied: pycryptodomex>=3.16.0 in /usr/local/lib/python3.10/dist-packages (from py7zr->voxel51-eta~=0.12->fiftyone) (3.19.0)\n",
            "Requirement already satisfied: pyzstd>=0.15.9 in /usr/local/lib/python3.10/dist-packages (from py7zr->voxel51-eta~=0.12->fiftyone) (0.15.9)\n",
            "Requirement already satisfied: pyppmd<1.2.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from py7zr->voxel51-eta~=0.12->fiftyone) (1.1.0)\n",
            "Requirement already satisfied: pybcj<1.1.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from py7zr->voxel51-eta~=0.12->fiftyone) (1.0.2)\n",
            "Requirement already satisfied: multivolumefile>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from py7zr->voxel51-eta~=0.12->fiftyone) (0.2.3)\n",
            "Requirement already satisfied: inflate64<1.1.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from py7zr->voxel51-eta~=0.12->fiftyone) (1.0.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from py7zr->voxel51-eta~=0.12->fiftyone) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->voxel51-eta~=0.12->fiftyone) (3.3.2)\n",
            "Requirement already satisfied: fiftyone-db-ubuntu2204 in /usr/local/lib/python3.10/dist-packages (0.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz"
      ],
      "metadata": {
        "id": "uXtlb8xCHmLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As agreed in the team discussion, we sample\n",
        "- 4000 data train\n",
        "- 500 data validation (splitted from train)\n",
        "- 500 data test (in validation split to compare performance model)"
      ],
      "metadata": {
        "id": "RdQZ_-DmSBEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the COCO-2017 dataset\n",
        "# This will download it from the FiftyOne Dataset Zoo if necessary\n",
        "\n",
        "dataset = foz.load_zoo_dataset(\"coco-2017\", split=\"train\", label_types=[\"detections\"], classes=[\"person\"], max_samples=4500, seed=43, dataset_dir=drive_dataset_path)\n",
        "dataset_test = foz.load_zoo_dataset(\"coco-2017\", split=\"validation\", label_types=[\"detections\"], classes=[\"person\"], max_samples=500, seed=43, dataset_dir=drive_dataset_path)\n",
        "\n",
        "# Print summary information about the view\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w38unbDjJtSY",
        "outputId": "343bf7d3-bd71-44ad-a607-7254abf0354b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading split 'train' to '/content/drive/MyDrive/cv_bootcamp_indonesiaai/project_2/dataset/train' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Downloading split 'train' to '/content/drive/MyDrive/cv_bootcamp_indonesiaai/project_2/dataset/train' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found annotations at '/content/drive/MyDrive/cv_bootcamp_indonesiaai/project_2/dataset/raw/instances_train2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Found annotations at '/content/drive/MyDrive/cv_bootcamp_indonesiaai/project_2/dataset/raw/instances_train2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sufficient images already downloaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Sufficient images already downloaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Existing download of split 'train' is sufficient\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Existing download of split 'train' is sufficient\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 'coco-2017' split 'train'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Loading 'coco-2017' split 'train'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |███████████████| 4500/4500 [39.0s elapsed, 0s remaining, 126.4 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |███████████████| 4500/4500 [39.0s elapsed, 0s remaining, 126.4 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 'coco-2017-train-4500' created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset 'coco-2017-train-4500' created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading split 'validation' to '/content/drive/MyDrive/cv_bootcamp_indonesiaai/project_2/dataset/validation' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Downloading split 'validation' to '/content/drive/MyDrive/cv_bootcamp_indonesiaai/project_2/dataset/validation' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found annotations at '/content/drive/MyDrive/cv_bootcamp_indonesiaai/project_2/dataset/raw/instances_val2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Found annotations at '/content/drive/MyDrive/cv_bootcamp_indonesiaai/project_2/dataset/raw/instances_val2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sufficient images already downloaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Sufficient images already downloaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Existing download of split 'validation' is sufficient\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Existing download of split 'validation' is sufficient\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 'coco-2017' split 'validation'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Loading 'coco-2017' split 'validation'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |█████████████████| 500/500 [3.4s elapsed, 0s remaining, 132.9 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |█████████████████| 500/500 [3.4s elapsed, 0s remaining, 132.9 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 'coco-2017-validation-500' created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset 'coco-2017-validation-500' created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name:        coco-2017-train-4500\n",
            "Media type:  image\n",
            "Num samples: 4500\n",
            "Persistent:  False\n",
            "Tags:        []\n",
            "Sample fields:\n",
            "    id:           fiftyone.core.fields.ObjectIdField\n",
            "    filepath:     fiftyone.core.fields.StringField\n",
            "    tags:         fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
            "    metadata:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
            "    ground_truth: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project we need the `person` class only for person detection. So, here we do filtering the detection to contain `person` class only"
      ],
      "metadata": {
        "id": "3UD7jKKsSmav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over the dataset\n",
        "for sample in dataset:\n",
        "    # Get the detections\n",
        "    detections = sample.ground_truth.detections\n",
        "    # Filter out non-person detections\n",
        "    detections = [d for d in detections if d.label == \"person\"]\n",
        "    # Update the detections\n",
        "    sample.ground_truth.detections = detections\n",
        "    # Save the sample\n",
        "    sample.save()"
      ],
      "metadata": {
        "id": "ze0eh2m2Kb8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over the dataset_test\n",
        "for sample in dataset_test:\n",
        "    # Get the detections\n",
        "    detections = sample.ground_truth.detections\n",
        "    # Filter out non-person detections\n",
        "    detections = [d for d in detections if d.label == \"person\"]\n",
        "    # Update the detections\n",
        "    sample.ground_truth.detections = detections\n",
        "    # Save the sample\n",
        "    sample.save()"
      ],
      "metadata": {
        "id": "b7k10EioK140"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if the ground truth detections label only `person` class"
      ],
      "metadata": {
        "id": "JjO0p-bMSdaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Classes list\n",
        "classes = dataset.distinct(\"ground_truth.detections.label\")\n",
        "print(len(classes))\n",
        "classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBo_2p8rJF8e",
        "outputId": "4e708625-70bf-429f-b99f-a1d52dc678bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['person']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare dependencies"
      ],
      "metadata": {
        "id": "8SMHFPdtIfEP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xbcXmrxINyQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "105c258d-53e8-4aa8-d5bb-0f2113f694bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-30 14:53:52--  https://raw.githubusercontent.com/pytorch/vision/main/references/detection/transforms.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23628 (23K) [text/plain]\n",
            "Saving to: ‘transforms.py.1’\n",
            "\n",
            "\rtransforms.py.1       0%[                    ]       0  --.-KB/s               \rtransforms.py.1     100%[===================>]  23.07K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-11-30 14:53:52 (128 MB/s) - ‘transforms.py.1’ saved [23628/23628]\n",
            "\n",
            "--2023-11-30 14:53:52--  https://raw.githubusercontent.com/pytorch/vision/main/references/detection/engine.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4063 (4.0K) [text/plain]\n",
            "Saving to: ‘engine.py.1’\n",
            "\n",
            "engine.py.1         100%[===================>]   3.97K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-11-30 14:53:52 (58.2 MB/s) - ‘engine.py.1’ saved [4063/4063]\n",
            "\n",
            "--2023-11-30 14:53:52--  https://raw.githubusercontent.com/pytorch/vision/main/references/detection/utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8388 (8.2K) [text/plain]\n",
            "Saving to: ‘utils.py.1’\n",
            "\n",
            "utils.py.1          100%[===================>]   8.19K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-11-30 14:53:52 (90.3 MB/s) - ‘utils.py.1’ saved [8388/8388]\n",
            "\n",
            "--2023-11-30 14:53:52--  https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_eval.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6447 (6.3K) [text/plain]\n",
            "Saving to: ‘coco_eval.py.1’\n",
            "\n",
            "coco_eval.py.1      100%[===================>]   6.30K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-11-30 14:53:52 (86.5 MB/s) - ‘coco_eval.py.1’ saved [6447/6447]\n",
            "\n",
            "--2023-11-30 14:53:52--  https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8397 (8.2K) [text/plain]\n",
            "Saving to: ‘coco_utils.py.1’\n",
            "\n",
            "coco_utils.py.1     100%[===================>]   8.20K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-11-30 14:53:52 (102 MB/s) - ‘coco_utils.py.1’ saved [8397/8397]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/transforms.py\n",
        "!wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/engine.py\n",
        "!wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/utils.py\n",
        "!wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_eval.py\n",
        "!wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_utils.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import dependencies"
      ],
      "metadata": {
        "id": "uU3eq09KMRKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "import torch\n",
        "import json\n",
        "import fiftyone.utils.coco as fouc\n",
        "from torchvision.io import read_image, ImageReadMode"
      ],
      "metadata": {
        "id": "PxIKPpFAIdpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create data loader"
      ],
      "metadata": {
        "id": "ugBshD6ENddb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ObjectDataset(torch.utils.data.Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        fiftyone_dataset,\n",
        "        transforms=None,\n",
        "        gt_field=\"ground_truth\",\n",
        "        classes=None,\n",
        "    ):\n",
        "        self.samples = fiftyone_dataset\n",
        "        self.transforms = transforms\n",
        "        self.gt_field = gt_field\n",
        "\n",
        "        self.img_paths = self.samples.values(\"filepath\")\n",
        "\n",
        "        self.classes = classes\n",
        "        if not self.classes:\n",
        "            # Get list of distinct labels that exist in the view\n",
        "            self.classes = self.samples.distinct(\n",
        "                \"%s.detections.label\" % gt_field\n",
        "            )\n",
        "\n",
        "        if self.classes[0] != \"background\":\n",
        "            self.classes = [\"background\"] + self.classes\n",
        "\n",
        "        self.labels_map_rev = {c: i for i, c in enumerate(self.classes)}\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        sample = self.samples[img_path]\n",
        "        metadata = sample.metadata\n",
        "        img = read_image(img_path, mode=ImageReadMode.RGB )\n",
        "\n",
        "        boxes = []\n",
        "        labels = []\n",
        "        area = []\n",
        "        iscrowd = []\n",
        "        detections = sample[self.gt_field].detections\n",
        "        for det in detections:\n",
        "            category_id = self.labels_map_rev[det.label]\n",
        "            coco_obj = fouc.COCOObject.from_label(\n",
        "                det, metadata, category_id=category_id,\n",
        "            )\n",
        "            x, y, w, h = coco_obj.bbox\n",
        "            boxes.append([x, y, x + w, y + h])\n",
        "            labels.append(coco_obj.category_id)\n",
        "            area.append(coco_obj.area)\n",
        "            iscrowd.append(coco_obj.iscrowd)\n",
        "\n",
        "        target = {}\n",
        "        target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        target[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64)\n",
        "        target[\"image_id\"] = torch.as_tensor([idx])\n",
        "        target[\"area\"] = torch.as_tensor(area, dtype=torch.float32)\n",
        "        target[\"iscrowd\"] = torch.as_tensor(iscrowd, dtype=torch.int64)\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            img, target = self.transforms(img, target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def get_classes(self):\n",
        "        return self.classes"
      ],
      "metadata": {
        "id": "759pqe0VNfXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import v2 as T\n",
        "\n",
        "def get_transform(train):\n",
        "    transforms = []\n",
        "    transforms.append(T.ToPILImage())\n",
        "    transforms.append(T.ToTensor())\n",
        "    transforms.append(T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)))\n",
        "    return T.Compose(transforms)"
      ],
      "metadata": {
        "id": "P0L7aIB_zktx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_split = dataset.take(4000)\n",
        "val_split = dataset.exclude(train_split)"
      ],
      "metadata": {
        "id": "Mfq2IeBGETY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch_dataset = ObjectDataset(train_split, get_transform(train=True))\n",
        "torch_dataset_val = ObjectDataset(val_split, get_transform(train=False))\n",
        "torch_dataset_test = ObjectDataset(dataset_test, get_transform(train=False))\n",
        "torch_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DH5OlGmuETHn",
        "outputId": "9d7b4c4c-9a7a-41ae-c4a8-7d96281ea22f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/v2/_deprecated.py:43: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.ObjectDataset at 0x78425da15060>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Model"
      ],
      "metadata": {
        "id": "RuRzPHPpNaX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor"
      ],
      "metadata": {
        "id": "Nu9liO0uYjkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Backbone Selection"
      ],
      "metadata": {
        "id": "yzwBaWk7TSMv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choose one either `GoogLeNet (Inception V1)` or `Inception V3` for the backbone of Faster R-CNN"
      ],
      "metadata": {
        "id": "djh13pjPTZXu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GoogLeNet (Inception V1)"
      ],
      "metadata": {
        "id": "RT7E_1S-Hq3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# backbone googlenet\n",
        "googlenet = torchvision.models.googlenet(weights=\"DEFAULT\")\n",
        "backbone = torch.nn.Sequential(*list(googlenet.children())[:-3])\n",
        "\n",
        "\n",
        "backbone.out_channels = 1024\n",
        "\n",
        "anchor_generator = AnchorGenerator()\n",
        "\n",
        "roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names= ['0'], output_size=7, sampling_ratio=2)\n",
        "\n",
        "model = FasterRCNN(backbone,\n",
        "                   num_classes=2,\n",
        "                   rpn_anchor_generator=anchor_generator,\n",
        "                   box_roi_pool=roi_pooler\n",
        "                   )"
      ],
      "metadata": {
        "id": "cS6EirjMNI3P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0415341-a9a5-4c93-b79d-8a380e15952c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /root/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n",
            "100%|██████████| 49.7M/49.7M [00:00<00:00, 56.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inception V3"
      ],
      "metadata": {
        "id": "uAXPaRUrHgCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inception = torchvision.models.inception_v3(pretrained=True)\n",
        "\n",
        "modules = list(inception.children())[:-3]\n",
        "modules.pop(-4)\n",
        "backbone = torch.nn.Sequential(*modules)\n",
        "\n",
        "\n",
        "backbone.out_channels = 2048\n",
        "\n",
        "anchor_generator = AnchorGenerator()\n",
        "\n",
        "roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names= ['0'], output_size=7, sampling_ratio=2)\n",
        "\n",
        "model = FasterRCNN(backbone, num_classes=2, rpn_anchor_generator=anchor_generator, box_roi_pool=roi_pooler)"
      ],
      "metadata": {
        "id": "j1MUi0pgYZeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23011910-58c1-4785-96bb-9383735f23ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model"
      ],
      "metadata": {
        "id": "MtayJiqBiDBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "\n",
        "def train(model, torch_dataset, torch_dataset_val, num_epochs=4):\n",
        "    # train on the GPU or on the CPU, if a GPU is not available\n",
        "    print(\"# train on the GPU or on the CPU, if a GPU is not available\")\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "    # our dataset has two classes only - background and person\n",
        "    print(\"# our dataset has two classes only - background and person\")\n",
        "    num_classes = 2\n",
        "\n",
        "    # define training and validation data loaders\n",
        "    print(\"# define training and validation data loaders\")\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        torch_dataset,\n",
        "        batch_size=4,\n",
        "        shuffle=True,\n",
        "        num_workers=4,\n",
        "        collate_fn=utils.collate_fn)\n",
        "\n",
        "    print(\"data_loader finished\")\n",
        "\n",
        "    data_loader_val = torch.utils.data.DataLoader(\n",
        "        torch_dataset_val, batch_size=2, shuffle=False, num_workers=4,\n",
        "        collate_fn=utils.collate_fn)\n",
        "    print(\"data_loader_val finished\")\n",
        "\n",
        "    # move model to the right device\n",
        "    print(\"# move model to the right device\")\n",
        "    model.to(device)\n",
        "\n",
        "    # construct an optimizer\n",
        "    print(\"# construct an optimizer\")\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = torch.optim.SGD(params, lr=0.0001, momentum=0.9, weight_decay=0.0001)\n",
        "    # and a learning rate scheduler\n",
        "    print(\"# and a learning rate scheduler\")\n",
        "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
        "                                                        milestones=[16,22],\n",
        "                                                #    step_size=3,\n",
        "                                                   gamma=0.1\n",
        "                                                        )\n",
        "\n",
        "    # let's train it for 10 epochs\n",
        "    print(f\"# let's train it for {num_epochs} epochs\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # train for one epoch, printing every 100 iterations\n",
        "        print(f\"# train for one epoch, printing every 100 iterations\")\n",
        "        train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=100)\n",
        "        # update the learning rate\n",
        "        print(\"# update the learning rate\")\n",
        "        lr_scheduler.step()\n",
        "        # evaluate on the test dataset\n",
        "        print(\"# evaluate on the val dataset\")\n",
        "        evaluate(model, data_loader_val, device=device)\n",
        "\n",
        "    print(\"That's it!\")\n",
        "\n",
        "def evaluate(model, torch_dataset_val, device):\n",
        "    cpu_device = torch.device(\"cpu\")\n",
        "    preds = []\n",
        "    targets = []\n",
        "    model.eval()\n",
        "    for img, target in torch_dataset_val:\n",
        "        with torch.no_grad():\n",
        "            pred = model([img[0].to(device)])\n",
        "            pred = [{k: v.to(cpu_device) for k, v in t.items()} for t in pred]\n",
        "            preds.append(pred)\n",
        "            targets.append(target)"
      ],
      "metadata": {
        "id": "B3XF0b2SNNQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, torch_dataset, torch_dataset_val, num_epochs=5)"
      ],
      "metadata": {
        "id": "Hv5amou6iJlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "XrFugPYlA8Jn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load trained model here based on selected backbone"
      ],
      "metadata": {
        "id": "lfH7qtEtHT1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model_path = '/content/drive/MyDrive/cv_bootcamp_indonesiaai/project_2/models/fasterrcnn_inceptionv3_model.pt'\n",
        "# state_dict = torch.load(model_path)\n",
        "# model.load_state_dict(state_dict)"
      ],
      "metadata": {
        "id": "XAuv1T56-doy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39e7453a-b2aa-4ec8-f4ff-0fd748f13a93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference Time"
      ],
      "metadata": {
        "id": "Wt-Y5SvqVZ82"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use it once at first run evaluation"
      ],
      "metadata": {
        "id": "7DmvtrhfVbrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "# Measure Inference Time\n",
        "\n",
        "def print_inference_time(model):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    image_paths = torch_dataset_test.img_paths\n",
        "    classes = torch_dataset_test.classes\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "    for img, targets in torch_dataset_test:\n",
        "        # Get FiftyOne sample indexed by unique image filepath\n",
        "        img_id = int(targets[\"image_id\"][0])\n",
        "        img_path = image_paths[img_id]\n",
        "        sample = dataset_test[img_path]\n",
        "\n",
        "        # Measure inference time\n",
        "        with torch.no_grad():\n",
        "            start_time = time.time()\n",
        "            preds = model(img.unsqueeze(0).to(device))[0]\n",
        "            end_time = time.time()\n",
        "\n",
        "        inference_time = end_time - start_time\n",
        "        print(f\"Inference time: {inference_time} seconds\")\n",
        "        break\n",
        "\n",
        "print_inference_time(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "M7bOad8wipXM",
        "outputId": "12d3d39a-df8e-489c-dd50-33aca934824f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-69d63606e277>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/detection/generalized_rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"targets should not be none when in training mode\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m_assert\u001b[0;34m(condition, message)\u001b[0m\n\u001b[1;32m   1402\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_assert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1404\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m \u001b[0;31m################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: targets should not be none when in training mode"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add predictions"
      ],
      "metadata": {
        "id": "7qZvbPhdVkUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_torch_predictions(preds, det_id, s_id, w, h, classes):\n",
        "    # Convert the outputs of the torch model into a FiftyOne Detections object\n",
        "    dets = []\n",
        "\n",
        "    for bbox, label, score in zip(\n",
        "        preds[\"boxes\"].cpu().detach().numpy(),\n",
        "        preds[\"labels\"].cpu().detach().numpy(),\n",
        "        preds[\"scores\"].cpu().detach().numpy()\n",
        "    ):\n",
        "        # Parse prediction into FiftyOne Detection object\n",
        "        x0,y0,x1,y1 = bbox\n",
        "        coco_obj = fouc.COCOObject(det_id, s_id, int(label), [x0, y0, x1-x0, y1-y0])\n",
        "        det = coco_obj.to_detection((w,h), classes)\n",
        "        det[\"confidence\"] = float(score)\n",
        "        dets.append(det)\n",
        "        det_id += 1\n",
        "\n",
        "    detections = fo.Detections(detections=dets)\n",
        "\n",
        "    return detections, det_id\n",
        "\n",
        "def add_detections(model, torch_dataset, view, field_name=\"predictions\"):\n",
        "    # Run inference on a dataset and add results to FiftyOne\n",
        "    torch.set_num_threads(1)\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "    print(\"Using device %s\" % device)\n",
        "\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    image_paths = torch_dataset.img_paths\n",
        "    classes = torch_dataset.classes\n",
        "    det_id = 0\n",
        "\n",
        "    with fo.ProgressBar() as pb:\n",
        "        for img, targets in pb(torch_dataset):\n",
        "            # Get FiftyOne sample indexed by unique image filepath\n",
        "            img_id = int(targets[\"image_id\"][0])\n",
        "            img_path = image_paths[img_id]\n",
        "            sample = view[img_path]\n",
        "            s_id = sample.id\n",
        "            w = sample.metadata[\"width\"]\n",
        "            h = sample.metadata[\"height\"]\n",
        "\n",
        "            # Inference\n",
        "            preds = model(img.unsqueeze(0).to(device))[0]\n",
        "\n",
        "            detections, det_id = convert_torch_predictions(\n",
        "                preds,\n",
        "                det_id,\n",
        "                s_id,\n",
        "                w,\n",
        "                h,\n",
        "                classes\n",
        "            )\n",
        "\n",
        "            sample[field_name] = detections\n",
        "            sample.save()\n",
        "\n",
        "\n",
        "# def convert_torch_predictions(preds, det_id, s_id, w, h, classes, nms_threshold=0.5):\n",
        "#     # Convert the outputs of the torch model into a FiftyOne Detections object\n",
        "#     dets = []\n",
        "\n",
        "#     # Apply NMS to the predictions\n",
        "#     keep = torchvision.ops.nms(preds[\"boxes\"], preds[\"scores\"], iou_threshold=nms_threshold)\n",
        "#     preds[\"boxes\"] = preds[\"boxes\"][keep]\n",
        "#     preds[\"labels\"] = preds[\"labels\"][keep]\n",
        "#     preds[\"scores\"] = preds[\"scores\"][keep]\n",
        "\n",
        "#     # # Filter detections based on confidence threshold\n",
        "#     # conf_mask = preds[\"scores\"] >= conf_threshold\n",
        "#     # preds[\"boxes\"] = preds[\"boxes\"][conf_mask]\n",
        "#     # preds[\"labels\"] = preds[\"labels\"][conf_mask]\n",
        "#     # preds[\"scores\"] = preds[\"scores\"][conf_mask]\n",
        "\n",
        "#     for bbox, label, score in zip(\n",
        "#         preds[\"boxes\"].cpu().detach().numpy(),\n",
        "#         preds[\"labels\"].cpu().detach().numpy(),\n",
        "#         preds[\"scores\"].cpu().detach().numpy()\n",
        "#     ):\n",
        "#         # Parse prediction into FiftyOne Detection object\n",
        "#         x0, y0, x1, y1 = bbox\n",
        "#         coco_obj = fouc.COCOObject(det_id, s_id, int(label), [x0, y0, x1 - x0, y1 - y0])\n",
        "#         det = coco_obj.to_detection((w, h), classes)\n",
        "#         det[\"confidence\"] = float(score)\n",
        "#         dets.append(det)\n",
        "#         det_id += 1\n",
        "\n",
        "#     detections = fo.Detections(detections=dets)\n",
        "\n",
        "#     return detections, det_id\n",
        "\n",
        "# def add_detections(model, torch_dataset, view, field_name=\"predictions\", nms_threshold=0.5):\n",
        "#     # Run inference on a dataset and add results to FiftyOne\n",
        "#     torch.set_num_threads(1)\n",
        "#     device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "#     print(\"Using device %s\" % device)\n",
        "\n",
        "#     model.eval()\n",
        "#     model.to(device)\n",
        "#     image_paths = torch_dataset.img_paths\n",
        "#     classes = torch_dataset.classes\n",
        "#     det_id = 0\n",
        "\n",
        "#     with fo.ProgressBar() as pb:\n",
        "#         for img, targets in pb(torch_dataset):\n",
        "#             # Get FiftyOne sample indexed by unique image filepath\n",
        "#             img_id = int(targets[\"image_id\"][0])\n",
        "#             img_path = image_paths[img_id]\n",
        "#             sample = view[img_path]\n",
        "#             s_id = sample.id\n",
        "#             w = sample.metadata[\"width\"]\n",
        "#             h = sample.metadata[\"height\"]\n",
        "\n",
        "#             # Inference\n",
        "#             preds = model(img.unsqueeze(0).to(device))[0]\n",
        "\n",
        "#             detections, det_id = convert_torch_predictions(\n",
        "#                 preds,\n",
        "#                 det_id,\n",
        "#                 s_id,\n",
        "#                 w,\n",
        "#                 h,\n",
        "#                 classes,\n",
        "#                 nms_threshold\n",
        "#             )\n",
        "\n",
        "#             sample[field_name] = detections\n",
        "#             sample.save()"
      ],
      "metadata": {
        "id": "ld8C_8cEqRct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add_detections(model, torch_dataset_test, dataset_test, field_name=\"predictions\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEpZOx76eIuZ",
        "outputId": "15cbc13b-278a-467c-ed36-855ba1491862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device cuda\n",
            "inference: 1.6528136730194092\n",
            "   0% |/----------------|   0/500 [1.7s elapsed, ? remaining, ? samples/s]   \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils:   0% |/----------------|   0/500 [1.7s elapsed, ? remaining, ? samples/s]   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('maps(0.5-0.95)', np.mean(np.array(maps)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaVVlBHOfc1S",
        "outputId": "db95d090-79cb-4d35-dfeb-998b534cc15f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maps(0.5-0.95) 0.1329818590102886\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = fo.evaluate_detections(\n",
        "  dataset_test,\n",
        "  \"predictions\",\n",
        "  classes=[\"person\"],\n",
        "  eval_key=\"eval\",\n",
        "  classwise=False,\n",
        "  compute_mAP=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQEtWQhPA-nP",
        "outputId": "25e3aab4-fbdc-474b-ab31-783023d6b419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating detections...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.eval.detection:Evaluating detections...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |█████████████████| 500/500 [1.7m elapsed, 0s remaining, 5.7 samples/s]        \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |█████████████████| 500/500 [1.7m elapsed, 0s remaining, 5.7 samples/s]        \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing IoU sweep...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.eval.coco:Performing IoU sweep...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |█████████████████| 500/500 [31.2s elapsed, 0s remaining, 22.5 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |█████████████████| 500/500 [31.2s elapsed, 0s remaining, 22.5 samples/s]      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### mAP Score"
      ],
      "metadata": {
        "id": "uXn2F1bGVss2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results.mAP()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpRwSiVtPs3d",
        "outputId": "526a5333-2807-450a-95f8-dd41378b99f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.13298185901028858"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classification Report"
      ],
      "metadata": {
        "id": "ylwOUZaPVwpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counts = dataset_test.count_values(\"ground_truth.detections.label\")\n",
        "counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJHdjX1zguBE",
        "outputId": "586a3a06-33bb-4641-f70b-352328fff701"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'person': 2090}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the 10 most common classes in the dataset\n",
        "classes_top = sorted(counts, key=counts.get, reverse=True)\n",
        "results.print_report(classes=classes_top)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRBo0WovPvjV",
        "outputId": "6af4c745-0294-4681-c28d-94ca7073ecc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      person       0.21      0.84      0.34      5012\n",
            "\n",
            "   micro avg       0.21      0.84      0.34      5012\n",
            "   macro avg       0.21      0.84      0.34      5012\n",
            "weighted avg       0.21      0.84      0.34      5012\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results.plot_pr_curves(classes=[\"person\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "J_mtBFicPpJd",
        "outputId": "8df434a3-f1b1-4013-a6b9-63f259767436"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"d34b049e-0c8c-4bc8-8f16-d96813fa67cf\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d34b049e-0c8c-4bc8-8f16-d96813fa67cf\")) {                    Plotly.newPlot(                        \"d34b049e-0c8c-4bc8-8f16-d96813fa67cf\",                        [{\"customdata\":[0.9750425815582275,0.8428227186203003,0.7485031127929688,0.7266603231430053,0.7007035136222839,0.6307568609714508,0.6173153698444367,0.6028504192829132,0.5842080533504486,0.5520166993141175,0.5050636112689972,0.49212525486946107,0.480131995677948,0.46415442824363706,0.44187059700489045,0.41741809248924255,0.39165013283491135,0.3656412184238434,0.3523777425289154,0.33754301965236666,0.3234840244054794,0.30794871747493746,0.29296618700027466,0.2756684452295303,0.2584915094077587,0.24137000143527984,0.2321212500333786,0.2212461769580841,0.21066379249095918,0.20082526206970214,0.19087192118167878,0.17969133704900742,0.16881709843873977,0.16062190085649491,0.14701436534523965,0.1301236242055893,0.12424524128437042,0.11694706082344056,0.1108628511428833,0.10444487035274505,0.09752050936222076,0.09278848767280579,0.08633623868227006,0.07923940420150757,0.07212325930595398,0.0659952387213707,0.060290385782718656,0.050087323784828185,0.04704244583845139,0.04342832267284393,0.03970586806535721,0.03622627854347229,0.031690388917922974,0.027712507545948027,0.024982988089323043,0.016996847093105318,0.014741776883602143,0.013382843136787415,0.010762532055377961,0.009299930930137635,0.008062417060136795,0.006215420365333557,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"hovertemplate\":\"\\u003cb\\u003eclass: %{text}\\u003c\\u002fb\\u003e\\u003cbr\\u003erecall: %{x:.3f}\\u003cbr\\u003eprecision: %{y:.3f}\\u003cbr\\u003ethreshold: %{customdata:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"line\":{\"color\":\"#FF6D04\"},\"mode\":\"lines\",\"name\":\"person (AP = 0.133)\",\"text\":[\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\"],\"x\":[0.0,0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1,0.11,0.12,0.13,0.14,0.15,0.16,0.17,0.18,0.19,0.2,0.21,0.22,0.23,0.24,0.25,0.26,0.27,0.28,0.29,0.3,0.31,0.32,0.33,0.34,0.35000000000000003,0.36,0.37,0.38,0.39,0.4,0.41000000000000003,0.42,0.43,0.44,0.45,0.46,0.47000000000000003,0.48,0.49,0.5,0.51,0.52,0.53,0.54,0.55,0.56,0.5700000000000001,0.58,0.59,0.6,0.61,0.62,0.63,0.64,0.65,0.66,0.67,0.68,0.6900000000000001,0.7000000000000001,0.71,0.72,0.73,0.74,0.75,0.76,0.77,0.78,0.79,0.8,0.81,0.8200000000000001,0.8300000000000001,0.84,0.85,0.86,0.87,0.88,0.89,0.9,0.91,0.92,0.93,0.9400000000000001,0.9500000000000001,0.96,0.97,0.98,0.99,1.0],\"y\":[0.8119999999999999,0.6120548850057047,0.599926891536064,0.5736510147237202,0.5474577400395921,0.5266895140802081,0.5075216881681721,0.49218422381913707,0.47590202877820903,0.44179152893633,0.4262380815309167,0.41281332739133225,0.40287706782166693,0.39074429019845025,0.37266655614194377,0.3511613900071645,0.3426616707676524,0.32940105132376657,0.31740516107505606,0.3049617406533099,0.2830430650411226,0.2748767738339715,0.26765784976744394,0.2562091446417136,0.24926255514112133,0.23604493871937865,0.20730948955330014,0.20196316596826555,0.19519286960659507,0.18936862533628931,0.18448264618114535,0.17616342830301346,0.167691977495061,0.1383955959423723,0.13014794965966484,0.11954182942557974,0.11524141700566634,0.08116945250581296,0.07779765030215367,0.0753673497292402,0.07288237885475055,0.04088355481117677,0.03987505384051638,0.0385596292347842,0.03710752430116292,0.03569910556443248,0.034303236484493196,0.02724217192742523,0.02663175009603329,0.02583633089128114,0.02485745316200028,0.023949902806265994,0.022500419392448567,0.021062228783776463,0.020222600859457984,0.012452997124529972,0.011709314227226203,0.011287820015515903,0.010223449227849193,0.009624600638977635,0.009064695009242143,0.008153916628492899,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(237,237,237)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(51,51,51)\"},\"error_y\":{\"color\":\"rgb(51,51,51)\"},\"marker\":{\"line\":{\"color\":\"rgb(237,237,237)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(51,51,51)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(51,51,51)\"},\"baxis\":{\"endlinecolor\":\"rgb(51,51,51)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(51,51,51)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(237,237,237)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(217,217,217)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"colorscale\":{\"sequential\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"sequentialminus\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]]},\"colorway\":[\"#F8766D\",\"#A3A500\",\"#00BF7D\",\"#00B0F6\",\"#E76BF3\"],\"font\":{\"color\":\"rgb(51,51,51)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"rgb(237,237,237)\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"rgb(237,237,237)\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"},\"bgcolor\":\"rgb(237,237,237)\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(237,237,237)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"rgb(237,237,237)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"rgb(237,237,237)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"fillcolor\":\"black\",\"line\":{\"width\":0},\"opacity\":0.3},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"},\"bgcolor\":\"rgb(237,237,237)\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"}},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\"}}},\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":1,\"y1\":0}],\"xaxis\":{\"range\":[0,1],\"constrain\":\"domain\",\"title\":{\"text\":\"Recall\"}},\"yaxis\":{\"range\":[0,1],\"constrain\":\"domain\",\"scaleanchor\":\"x\",\"scaleratio\":1,\"title\":{\"text\":\"Precision\"}},\"title\":{},\"margin\":{\"r\":0,\"t\":30,\"l\":0,\"b\":0}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d34b049e-0c8c-4bc8-8f16-d96813fa67cf');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results.plot_confusion_matrix()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "id": "642KgIDtPqU9",
        "outputId": "aa90cd7c-3b36-47ef-90a5-7db228af488d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/fiftyone/core/plots/plotly.py:1575: UserWarning:\n",
            "\n",
            "Interactive plots are currently only supported in Jupyter notebooks. Support outside of notebooks and in Google Colab and Databricks will be included in an upcoming release. In the meantime, you can still use this plot, but note that (i) selecting data will not trigger callbacks, and (ii) you must manually call `plot.show()` to launch a new plot that reflects the current state of an attached session.\n",
            "\n",
            "See https://docs.voxel51.com/user_guide/plots.html#working-in-notebooks for more information.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"a7c4e9a5-f8a5-48fd-9804-7a89516ca846\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a7c4e9a5-f8a5-48fd-9804-7a89516ca846\")) {                    Plotly.newPlot(                        \"a7c4e9a5-f8a5-48fd-9804-7a89516ca846\",                        [{\"mode\":\"markers\",\"opacity\":0.1,\"x\":[0,1,0,1],\"y\":[0,0,1,1],\"type\":\"scatter\",\"uid\":\"0630a27c-38f6-411d-934f-adebb49d9e68\"},{\"colorscale\":[[0.0,\"rgb(255,245,235)\"],[0.125,\"rgb(254,230,206)\"],[0.25,\"rgb(253,208,162)\"],[0.375,\"rgb(253,174,107)\"],[0.5,\"rgb(253,141,60)\"],[0.625,\"rgb(241,105,19)\"],[0.75,\"rgb(217,72,1)\"],[0.875,\"rgb(166,54,3)\"],[1.0,\"rgb(127,39,4)\"]],\"hoverinfo\":\"skip\",\"showscale\":false,\"z\":[[15544,0],[4226,786]],\"zmax\":15544,\"zmin\":0,\"type\":\"heatmap\",\"uid\":\"fe35943a-78d3-489a-9acd-f3ebe6ca4573\"},{\"colorbar\":{\"len\":1,\"lenmode\":\"fraction\"},\"colorscale\":[[0.0,\"rgb(255,245,235)\"],[0.125,\"rgb(254,230,206)\"],[0.25,\"rgb(253,208,162)\"],[0.375,\"rgb(253,174,107)\"],[0.5,\"rgb(253,141,60)\"],[0.625,\"rgb(241,105,19)\"],[0.75,\"rgb(217,72,1)\"],[0.875,\"rgb(166,54,3)\"],[1.0,\"rgb(127,39,4)\"]],\"hovertemplate\":\"\\u003cb\\u003ecount: %{z}\\u003c\\u002fb\\u003e\\u003cbr\\u003etruth: %{y}\\u003cbr\\u003epredicted: %{x}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"opacity\":0.25,\"z\":[[15544,0],[4226,786]],\"zmax\":15544,\"zmin\":0,\"type\":\"heatmap\",\"uid\":\"0d786ec8-ed0e-40c5-8e5f-8ed3fae10dd3\"}],                        {\"clickmode\":\"event\",\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(237,237,237)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(51,51,51)\"},\"error_y\":{\"color\":\"rgb(51,51,51)\"},\"marker\":{\"line\":{\"color\":\"rgb(237,237,237)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(51,51,51)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(51,51,51)\"},\"baxis\":{\"endlinecolor\":\"rgb(51,51,51)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(51,51,51)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(237,237,237)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(217,217,217)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"colorscale\":{\"sequential\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"sequentialminus\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]]},\"colorway\":[\"#F8766D\",\"#A3A500\",\"#00BF7D\",\"#00B0F6\",\"#E76BF3\"],\"font\":{\"color\":\"rgb(51,51,51)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"rgb(237,237,237)\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"rgb(237,237,237)\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"},\"bgcolor\":\"rgb(237,237,237)\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(237,237,237)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"rgb(237,237,237)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"rgb(237,237,237)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"fillcolor\":\"black\",\"line\":{\"width\":0},\"opacity\":0.3},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"},\"bgcolor\":\"rgb(237,237,237)\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"}},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\"}}},\"xaxis\":{\"constrain\":\"domain\",\"range\":[-0.5,1.5],\"tickmode\":\"array\",\"ticktext\":[\"person\",\"(none)\"],\"tickvals\":[0,1]},\"yaxis\":{\"constrain\":\"domain\",\"range\":[-0.5,1.5],\"scaleanchor\":\"x\",\"scaleratio\":1,\"tickmode\":\"array\",\"ticktext\":[\"(none)\",\"person\"],\"tickvals\":[0,1]},\"margin\":{\"r\":0,\"t\":30,\"l\":0,\"b\":0},\"title\":{}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a7c4e9a5-f8a5-48fd-9804-7a89516ca846');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save model"
      ],
      "metadata": {
        "id": "GEQAuJc0HXPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/cv_bootcamp_indonesiaai/project_2/models/fasterrcnn_inceptionv3_model.pt')"
      ],
      "metadata": {
        "id": "sl-rnFKbNNc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Visualization"
      ],
      "metadata": {
        "id": "RCim9ulvHYS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fiftyone import ViewField as F"
      ],
      "metadata": {
        "id": "GQxOHBYLPZNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "session = fo.launch_app(dataset_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_VOzcaanRo9O",
        "outputId": "a7033d36-09e7-4f34-b07d-c0556cf2d32a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "@import url(\"https://fonts.googleapis.com/css2?family=Palanquin&display=swap\");\n",
              "\n",
              "body, html {\n",
              "  margin: 0;\n",
              "  padding: 0;\n",
              "  width: 100%;\n",
              "}\n",
              "\n",
              "#focontainer-9bc15d50-d712-4b24-8042-64b77821d38e {\n",
              "  position: relative;\n",
              "  height: px;\n",
              "  display: block !important;\n",
              "}\n",
              "#foactivate-9bc15d50-d712-4b24-8042-64b77821d38e {\n",
              "  font-weight: bold;\n",
              "  cursor: pointer;\n",
              "  font-size: 24px;\n",
              "  border-radius: 3px;\n",
              "  text-align: center;\n",
              "  padding: 0.5em;\n",
              "  color: rgb(255, 255, 255);\n",
              "  font-family: \"Palanquin\", sans-serif;\n",
              "  position: absolute;\n",
              "  left: 50%;\n",
              "  top: 50%;\n",
              "  width: 160px;\n",
              "  margin-left: -80px;\n",
              "  margin-top: -23px;\n",
              "  background: hsla(210,11%,15%, 0.8);\n",
              "  border: none;\n",
              "}\n",
              "#foactivate-9bc15d50-d712-4b24-8042-64b77821d38e:focus {\n",
              "  outline: none;\n",
              "}\n",
              "#fooverlay-9bc15d50-d712-4b24-8042-64b77821d38e {\n",
              "  width: 100%;\n",
              "  height: 100%;\n",
              "  background: hsla(208, 7%, 46%, 0.7);\n",
              "  position: absolute;\n",
              "  top: 0;\n",
              "  left: 0;\n",
              "  display: none;\n",
              "  cursor: pointer;\n",
              "}\n",
              "</style>\n",
              "<div id=\"focontainer-9bc15d50-d712-4b24-8042-64b77821d38e\" style=\"display: none;\">\n",
              "   <div id=\"fooverlay-9bc15d50-d712-4b24-8042-64b77821d38e\">\n",
              "      <button id=\"foactivate-9bc15d50-d712-4b24-8042-64b77821d38e\" >Activate</button>\n",
              "   </div>\n",
              "</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Welcome to\n",
            "\n",
            "███████╗██╗███████╗████████╗██╗   ██╗ ██████╗ ███╗   ██╗███████╗\n",
            "██╔════╝██║██╔════╝╚══██╔══╝╚██╗ ██╔╝██╔═══██╗████╗  ██║██╔════╝\n",
            "█████╗  ██║█████╗     ██║    ╚████╔╝ ██║   ██║██╔██╗ ██║█████╗\n",
            "██╔══╝  ██║██╔══╝     ██║     ╚██╔╝  ██║   ██║██║╚██╗██║██╔══╝\n",
            "██║     ██║██║        ██║      ██║   ╚██████╔╝██║ ╚████║███████╗\n",
            "╚═╝     ╚═╝╚═╝        ╚═╝      ╚═╝    ╚═════╝ ╚═╝  ╚═══╝╚══════╝ v0.22.3\n",
            "\n",
            "If you're finding FiftyOne helpful, here's how you can get involved:\n",
            "\n",
            "|\n",
            "|  ⭐⭐⭐ Give the project a star on GitHub ⭐⭐⭐\n",
            "|  https://github.com/voxel51/fiftyone\n",
            "|\n",
            "|  🚀🚀🚀 Join the FiftyOne Slack community 🚀🚀🚀\n",
            "|  https://slack.voxel51.com\n",
            "|\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.core.session.session:\n",
            "Welcome to\n",
            "\n",
            "███████╗██╗███████╗████████╗██╗   ██╗ ██████╗ ███╗   ██╗███████╗\n",
            "██╔════╝██║██╔════╝╚══██╔══╝╚██╗ ██╔╝██╔═══██╗████╗  ██║██╔════╝\n",
            "█████╗  ██║█████╗     ██║    ╚████╔╝ ██║   ██║██╔██╗ ██║█████╗\n",
            "██╔══╝  ██║██╔══╝     ██║     ╚██╔╝  ██║   ██║██║╚██╗██║██╔══╝\n",
            "██║     ██║██║        ██║      ██║   ╚██████╔╝██║ ╚████║███████╗\n",
            "╚═╝     ╚═╝╚═╝        ╚═╝      ╚═╝    ╚═════╝ ╚═╝  ╚═══╝╚══════╝ v0.22.3\n",
            "\n",
            "If you're finding FiftyOne helpful, here's how you can get involved:\n",
            "\n",
            "|\n",
            "|  ⭐⭐⭐ Give the project a star on GitHub ⭐⭐⭐\n",
            "|  https://github.com/voxel51/fiftyone\n",
            "|\n",
            "|  🚀🚀🚀 Join the FiftyOne Slack community 🚀🚀🚀\n",
            "|  https://slack.voxel51.com\n",
            "|\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion"
      ],
      "metadata": {
        "id": "-cGnMxX-V1MG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In this experiment, Faster R-CNN with backbone `GoogLeNet Inception V1` and `Inception V3` produce low metrics with mAP below `0.2` and consume lots of training time (took 2 to 2,5 hours approx for 5 epochs only)\n",
        "- It took quite long inference time around 1 second for 1 input image\n",
        "- The prediction seems to be contain many bounding boxes for single ground truth detections\n",
        "- Although seems to be quite good for predicting single and big ground truth detections, but the model performs very bad on crowd and small ground truth detections"
      ],
      "metadata": {
        "id": "QuNzUMBkV27W"
      }
    }
  ]
}